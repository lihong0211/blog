<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>模型微调实验层（Finetuning） | 技术文档</title>
    <meta name="description" content="技术学习文档集合">
    <link rel="stylesheet" href="/assets/style.db59e0d6.css">
    <link rel="modulepreload" href="/assets/app.bf2af4c6.js">
    <link rel="modulepreload" href="/assets/AI_home_09_finetuning.md.224b6c0b.lean.js">
    
    <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-9c83c81e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-be9c27de></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-be9c27de> Skip to content </a><!--]--><!----><header class="VPNav no-sidebar" data-v-9c83c81e data-v-bd98ce1b><div class="VPNavBar" data-v-bd98ce1b data-v-be850364><div class="container" data-v-be850364><div class="VPNavBarTitle" data-v-be850364 data-v-ef6bdfee><a class="title" href="/" data-v-ef6bdfee><!--[--><!--]--><!----><!--[-->技术文档<!--]--><!--[--><!--]--></a></div><div class="content" data-v-be850364><!--[--><!--]--><!----><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-be850364 data-v-4f0f7d90><span id="main-nav-aria-label" class="visually-hidden" data-v-4f0f7d90>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" data-v-4f0f7d90 data-v-d1df1d79 data-v-cbb71e82><!--[-->首页<!--]--><!----></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-be850364 data-v-6975dfb0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-6975dfb0 data-v-a11464a8 data-v-9b61e15c><span class="check" data-v-9b61e15c><span class="icon" data-v-9b61e15c><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-a11464a8><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-a11464a8><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-be850364 data-v-9d62d057 data-v-2aee37ba><!--[--><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-be850364 data-v-af83da42 data-v-0bf5642f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-0bf5642f><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-0bf5642f><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-0bf5642f><div class="VPMenu" data-v-0bf5642f data-v-958884f0><!----><!--[--><!--[--><!----><div class="group" data-v-af83da42><div class="item appearance" data-v-af83da42><p class="label" data-v-af83da42>Appearance</p><div class="appearance-action" data-v-af83da42><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-af83da42 data-v-a11464a8 data-v-9b61e15c><span class="check" data-v-9b61e15c><span class="icon" data-v-9b61e15c><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-a11464a8><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-a11464a8><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-af83da42><div class="item social-links" data-v-af83da42><div class="VPSocialLinks social-links-list" data-v-af83da42 data-v-2aee37ba><!--[--><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-be850364 data-v-cd76eed2><span class="container" data-v-cd76eed2><span class="top" data-v-cd76eed2></span><span class="middle" data-v-cd76eed2></span><span class="bottom" data-v-cd76eed2></span></span></button></div></div></div><!----></header><!----><!----><div class="VPContent" id="VPContent" data-v-9c83c81e data-v-954ad629><div class="VPDoc has-aside" data-v-954ad629 data-v-dc19973f><div class="container" data-v-dc19973f><div class="aside" data-v-dc19973f><div class="aside-curtain" data-v-dc19973f></div><div class="aside-container" data-v-dc19973f><div class="aside-content" data-v-dc19973f><div class="VPDocAside" data-v-dc19973f data-v-63938968><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" data-v-63938968 data-v-72b1abc9><div class="content" data-v-72b1abc9><div class="outline-marker" data-v-72b1abc9></div><div class="outline-title" data-v-72b1abc9>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-72b1abc9><span class="visually-hidden" id="doc-outline-aria-label" data-v-72b1abc9> Table of Contents for current page </span><ul class="root" data-v-72b1abc9 data-v-a950ca15><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-63938968></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-dc19973f><div class="content-container" data-v-dc19973f><!--[--><!--]--><main class="main" data-v-dc19973f><div style="position:relative;" class="vp-doc _AI_home_09_finetuning" data-v-dc19973f><div><h1 id="模型微调实验层-finetuning" tabindex="-1">模型微调实验层（Finetuning） <a class="header-anchor" href="#模型微调实验层-finetuning" aria-hidden="true">#</a></h1><blockquote><p>文件：<code>service/ai/finetuning/</code>（Qwen2_5_(7B)<em><a href="http://alpaca.py" target="_blank" rel="noreferrer">alpaca.py</a>、Qwen2_5</em>(7B)<em><a href="http://medical.py" target="_blank" rel="noreferrer">medical.py</a>、Qwen2_5</em>(7B)_R1.py、qwen_vl_car_insurance_train.py、image_svd/、MovieLens/ 等）</p></blockquote><hr><h2 id="第一部分-技术背景与演进" tabindex="-1">第一部分：技术背景与演进 <a class="header-anchor" href="#第一部分-技术背景与演进" aria-hidden="true">#</a></h2><p><strong>问题背景</strong></p><p>通用大模型（GPT-4、Qwen-7B）在通用任务上表现优秀，但面对高度专业化场景（医疗诊断、法律条文、特定格式输出）时，它们的回答往往不够精确、不符合行业术语规范，或者需要大量 Prompt 工程才能勉强达标。微调（Finetuning）通过在领域数据上继续训练模型，让模型&quot;内化&quot;领域知识和输出风格，从根本上解决通用模型的领域适应问题。</p><p><strong>核心概念</strong></p><ul><li><strong>SFT（监督式微调）</strong>：用&quot;问题-答案&quot;对训练模型学会特定格式和领域知识，是最常见的微调方式。</li><li><strong>LoRA（低秩适配器）</strong>：不改动原始权重，只在关键层旁边插入小矩阵（低秩矩阵）进行训练。7B 参数模型用 LoRA 微调只需更新约 0.1% 的参数，显存需求从 80GB 降至 10GB 以内。</li><li><strong>GRPO（生成奖励配对优化）</strong>：DeepSeek R1 提出的方法，通过多目标奖励函数（答案正确性 + 格式合规性 + 推理链质量）引导模型学会&quot;先推理后作答&quot;的思考风格。</li><li><strong>Unsloth</strong>：开源微调加速框架，通过 Flash Attention 2 + Triton 内核优化，使 SFT 速度提升 2-5 倍，显存占用减少约 60%。</li></ul><p><strong>演进脉络</strong></p><table><thead><tr><th>阶段</th><th>方案</th><th>特点</th></tr></thead><tbody><tr><td>早期</td><td>全量参数微调（Full Fine-tuning）</td><td>效果好，但需要数十 GB 显存，成本高</td></tr><tr><td>2021</td><td>Adapter 方法</td><td>插入小模块，参数量少，但速度有损</td></tr><tr><td>2021</td><td><strong>LoRA</strong>（微软）</td><td>低秩矩阵，参数量极少，速度接近全量</td></tr><tr><td>2023</td><td>QLoRA</td><td>LoRA + 4bit 量化，消费级 GPU 可微调 7B+ 模型</td></tr><tr><td>2024</td><td><strong>GRPO / DPO</strong></td><td>奖励信号驱动，训练推理能力而非仅输出格式</td></tr><tr><td>2024</td><td><strong>Unsloth</strong></td><td>工程加速，让 LoRA 训练快 2-5 倍</td></tr></tbody></table><p><strong>本模块的定位</strong></p><p><code>finetuning/</code> 目录是独立于主服务的实验脚本集合，不提供 HTTP 接口，直接在 GPU 机器上运行训练。涵盖三种典型微调场景和一套线性代数/推荐系统实验，是理解&quot;如何从通用模型定制领域模型&quot;的完整参考实现。</p><hr><h2 id="第二部分-架构剖析" tabindex="-1">第二部分：架构剖析 <a class="header-anchor" href="#第二部分-架构剖析" aria-hidden="true">#</a></h2><p><strong>四个微调脚本的技术对比</strong></p><table><thead><tr><th>脚本</th><th>模型</th><th>任务类型</th><th>训练器</th><th>数据来源</th><th>输出</th></tr></thead><tbody><tr><td><code>qwen_vl_car_insurance_train.py</code></td><td>Qwen2.5-VL-3B</td><td>视觉+文本 SFT</td><td>SFTTrainer + VisionDataCollator</td><td>qwen-vl-train.xlsx</td><td>car_insurance_lora_model</td></tr><tr><td><code>Qwen2_5_(7B)_medical.py</code></td><td>Qwen2.5-7B</td><td>文本 SFT</td><td>SFTTrainer</td><td>Data_数据/*.csv</td><td>lora_model_medical</td></tr><tr><td><code>Qwen2_5_(7B)_alpaca.py</code></td><td>Qwen2.5-7B</td><td>文本 SFT</td><td>SFTTrainer</td><td>alpaca-cleaned</td><td>lora_model</td></tr><tr><td><code>Qwen2_5_(7B)_R1.py</code></td><td>Qwen2.5-7B</td><td>GRPO 推理优化</td><td>GRPOTrainer</td><td>GSM8K</td><td>grpo_saved_lora</td></tr></tbody></table><p><strong>SFT 微调完整流程</strong></p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki"><code><span class="line"><span style="color:#A6ACCD;">1. 加载基座模型（4bit 量化，减少显存）</span></span>
<span class="line"><span style="color:#A6ACCD;">   FastLanguageModel.from_pretrained(&quot;Qwen2.5-7B-Instruct&quot;, load_in_4bit=True)</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">2. 注入 LoRA Adapter</span></span>
<span class="line"><span style="color:#A6ACCD;">   get_peft_model(model, r=16, lora_alpha=16,</span></span>
<span class="line"><span style="color:#A6ACCD;">                  target_modules=[&quot;q_proj&quot;, &quot;k_proj&quot;, &quot;v_proj&quot;, &quot;o_proj&quot;, ...])</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">3. 准备数据集（格式：{text: &quot;Prompt + EOS_TOKEN&quot;}）</span></span>
<span class="line"><span style="color:#A6ACCD;">   formatting_prompts_func → 拼 system + user + assistant</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">4. 训练（SFTTrainer）</span></span>
<span class="line"><span style="color:#A6ACCD;">   num_train_epochs=3 / max_steps=60</span></span>
<span class="line"><span style="color:#A6ACCD;">   per_device_train_batch_size=2</span></span>
<span class="line"><span style="color:#A6ACCD;">   gradient_accumulation_steps=4</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">5. 保存 LoRA 权重（约 100-300MB）</span></span>
<span class="line"><span style="color:#A6ACCD;">   model.save_pretrained(&quot;lora_model_medical&quot;)</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">6. 推理测试</span></span>
<span class="line"><span style="color:#A6ACCD;">   FastLanguageModel.for_inference(model)  # 开启推理优化</span></span>
<span class="line"><span style="color:#A6ACCD;">   model.generate(...)</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span></code></pre></div><p><strong>GRPO 推理微调流程（<a href="http://R1.py" target="_blank" rel="noreferrer">R1.py</a>）</strong></p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki"><code><span class="line"><span style="color:#A6ACCD;">训练目标：让 Qwen2.5-7B 输出 &lt;reasoning&gt;...&lt;/reasoning&gt;&lt;answer&gt;...&lt;/answer&gt; 格式</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">奖励函数组合（多目标）：</span></span>
<span class="line"><span style="color:#A6ACCD;">  ┌── correctness_reward_func   答案正确 → +2.0</span></span>
<span class="line"><span style="color:#A6ACCD;">  ├── int_reward_func           答案为整数 → +0.5</span></span>
<span class="line"><span style="color:#A6ACCD;">  ├── strict_format_reward_func 严格 XML 格式 → +0.5</span></span>
<span class="line"><span style="color:#A6ACCD;">  ├── soft_format_reward_func   宽松格式匹配 → +0.5</span></span>
<span class="line"><span style="color:#A6ACCD;">  └── xmlcount_reward_func      XML 标签完整性细粒度得分</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">GRPOTrainer：</span></span>
<span class="line"><span style="color:#A6ACCD;">  num_generations=6    每个 prompt 生成 6 个样本对比</span></span>
<span class="line"><span style="color:#A6ACCD;">  max_steps=250</span></span>
<span class="line"><span style="color:#A6ACCD;">  使用 vLLM fast_generate 加速 rollout</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span></code></pre></div><p><strong>视觉微调（qwen_vl_car_insurance_train.py）</strong></p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki"><code><span class="line"><span style="color:#A6ACCD;">输入数据格式（Excel → 对话格式）：</span></span>
<span class="line"><span style="color:#A6ACCD;">  user:      [TextPart: &quot;请从图中提取关键信息&quot;] + [ImagePart: 车辆里程表图片]</span></span>
<span class="line"><span style="color:#A6ACCD;">  assistant: &quot;里程数：12,345 公里，仪表盘状态正常...&quot;</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">关键配置：</span></span>
<span class="line"><span style="color:#A6ACCD;">  finetune_vision_layers=True    同时微调视觉编码器</span></span>
<span class="line"><span style="color:#A6ACCD;">  finetune_language_layers=True  同时微调语言解码器</span></span>
<span class="line"><span style="color:#A6ACCD;">  UnslothVisionDataCollator      处理混合文本+图片的 Batch 整理</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span></code></pre></div><p><strong>附加实验模块</strong></p><table><thead><tr><th>模块</th><th>内容</th></tr></thead><tbody><tr><td><code>image_svd/image_svd.py</code></td><td>用 NumPy SVD（奇异值分解）实现图片压缩，演示 LoRA 的数学基础</td></tr><tr><td><code>MovieLens/ALS.py</code></td><td>交替最小二乘（ALS）矩阵分解推荐系统，同样是低秩矩阵应用</td></tr><tr><td><code>dataset_legal.py</code></td><td>法律领域数据集构建工具</td></tr></tbody></table><p><code>image_svd</code> 和 <code>MovieLens/ALS</code> 是 LoRA 的数学概念演示——LoRA 本质上是对权重矩阵做低秩近似，和 SVD 图片压缩、ALS 矩阵分解同属&quot;用低秩矩阵近似高维矩阵&quot;的思想。</p><p><strong>与行业标准方案对比</strong></p><table><thead><tr><th>维度</th><th>Unsloth + LoRA（本项目）</th><th>HuggingFace PEFT + Trainer</th><th>LLaMA-Factory</th></tr></thead><tbody><tr><td>速度</td><td>2-5x 于标准 HF</td><td>基准</td><td>~2x（依赖 HF Trainer）</td></tr><tr><td>显存效率</td><td>最优（~60% 节省）</td><td>标准</td><td>中等</td></tr><tr><td>支持模型</td><td>Qwen/Llama/Mistral 等热门</td><td>几乎所有 HF 模型</td><td>Qwen/Llama 等</td></tr><tr><td>GRPO 支持</td><td>原生（配合 TRL GRPOTrainer）</td><td>需 TRL</td><td>有限</td></tr><tr><td>UI 界面</td><td>无（纯脚本）</td><td>无</td><td>有（Web UI）</td></tr><tr><td><strong>选型建议</strong></td><td>速度优先、Qwen 系列、资源受限</td><td>通用兼容、模型多样性</td><td>需要 UI 配置、不想写代码</td></tr></tbody></table><hr><h2 id="第三部分-代码实现深度解析" tabindex="-1">第三部分：代码实现深度解析 <a class="header-anchor" href="#第三部分-代码实现深度解析" aria-hidden="true">#</a></h2><p><strong>核心设计决策</strong></p><p><strong>决策 1：4bit 量化 + LoRA 的组合（QLoRA）</strong></p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki"><code><span class="line"><span style="color:#A6ACCD;">model</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> tokenizer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">from_pretrained</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Qwen2.5-7B-Instruct</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;">load_in_4bit</span><span style="color:#89DDFF;">=True,</span><span style="color:#82AAFF;">         </span><span style="color:#676E95;"># 4bit NF4 量化，7B 显存约 5-6GB</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;">dtype</span><span style="color:#89DDFF;">=None,</span><span style="color:#82AAFF;">                </span><span style="color:#676E95;"># 自动选择（bf16/fp16）</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">model </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">get_peft_model</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    model</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;">r</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">16</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;">                      </span><span style="color:#676E95;"># LoRA 秩：值越大参数越多，默认 16 是均衡选择</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;">lora_alpha</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">16</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;">             </span><span style="color:#676E95;"># 通常设为等于 r</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;">target_modules</span><span style="color:#89DDFF;">=[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">q_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">k_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">v_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">o_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gate_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">up_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">down_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">],</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><p>4bit 量化让 7B 模型从约 14GB 显存需求降至 5-6GB，单块 T4（16GB 显存）即可训练。LoRA 只训练约 0.1% 的参数，保留原始模型能力的同时学习领域知识。</p><p><strong>决策 2：医疗数据集的多编码容错</strong></p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki"><code><span class="line"><span style="color:#89DDFF;">for</span><span style="color:#A6ACCD;"> enc </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">utf-8</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gbk</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gb18030</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">utf-8-sig</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]:</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">try</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        df </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> pd</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">read_csv</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">f</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;">encoding</span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;">enc</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">break</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">except</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">UnicodeDecodeError</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">continue</span></span>
<span class="line"></span></code></pre></div><p>医疗数据来自多个来源，编码不统一。逐一尝试常见编码而不是要求统一格式，提升了数据加载的鲁棒性。同时对过长 QA 对（&gt;200 字）做过滤，避免训练数据噪声。</p><p><strong>决策 3：GRPO 多目标奖励分层设计</strong></p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki"><code><span class="line"><span style="color:#A6ACCD;">reward_funcs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#A6ACCD;">    correctness_reward_func</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;"># 最高权重：结果正确最重要</span></span>
<span class="line"><span style="color:#A6ACCD;">    int_reward_func</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">           </span><span style="color:#676E95;"># 辅助：答案格式（整数）</span></span>
<span class="line"><span style="color:#A6ACCD;">    strict_format_reward_func</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;"># 格式合规性（严格 XML）</span></span>
<span class="line"><span style="color:#A6ACCD;">    soft_format_reward_func</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;"># 格式合规性（宽松匹配）</span></span>
<span class="line"><span style="color:#A6ACCD;">    xmlcount_reward_func</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">      </span><span style="color:#676E95;"># 细粒度标签完整性</span></span>
<span class="line"><span style="color:#89DDFF;">]</span></span>
<span class="line"></span></code></pre></div><p>多目标奖励确保模型同时优化&quot;结果正确&quot;和&quot;格式合规&quot;，防止模型为了得高分只学格式忽略正确性（或反之）。</p><p><strong>决策 4：<code>image_svd</code> 演示 LoRA 的数学直觉</strong></p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki"><code><span class="line"><span style="color:#676E95;"># SVD 分解图片矩阵，只保留前 k 个奇异值</span></span>
<span class="line"><span style="color:#A6ACCD;">U</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> S</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> Vt </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">linalg</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">svd</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">img_channel</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">reconstructed </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> U</span><span style="color:#89DDFF;">[:,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;">k</span><span style="color:#89DDFF;">]</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">@</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">diag</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">S</span><span style="color:#89DDFF;">[:</span><span style="color:#82AAFF;">k</span><span style="color:#89DDFF;">])</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">@</span><span style="color:#A6ACCD;"> Vt</span><span style="color:#89DDFF;">[:</span><span style="color:#A6ACCD;">k</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">:]</span></span>
<span class="line"><span style="color:#676E95;"># k 越小，压缩率越高，图片越模糊</span></span>
<span class="line"><span style="color:#676E95;"># LoRA 的核心思想与此完全相同：用低秩矩阵 A×B 近似全秩权重矩阵 W</span></span>
<span class="line"></span></code></pre></div><p>这个可视化实验让&quot;为什么 LoRA 只需要小矩阵就能有效调整大模型行为&quot;变得直观可理解。</p><hr><h2 id="第四部分-应用场景与实战" tabindex="-1">第四部分：应用场景与实战 <a class="header-anchor" href="#第四部分-应用场景与实战" aria-hidden="true">#</a></h2><p><strong>使用场景</strong></p><ul><li><strong>医疗领域专家模型</strong>：Qwen2.5-7B 在医疗 QA 数据上 SFT，输出专业医疗建议（研究/演示用途，非正式医疗建议）</li><li><strong>视觉理解应用</strong>：Qwen2.5-VL-3B 在车险图片上微调，自动从汽车照片提取关键信息，支持保险核保自动化</li><li><strong>推理能力增强</strong>：用 GRPO 让 Qwen2.5-7B 学会 DeepSeek-R1 风格的思维链推理，提升数学/逻辑任务准确率</li><li><strong>概念学习</strong>：<code>image_svd</code> 和 <code>MovieLens/ALS</code> 是理解 LoRA 低秩近似思想的最佳可视化入门</li></ul><p><strong>环境依赖</strong></p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki"><code><span class="line"><span style="color:#676E95;"># 主要依赖（建议 AutoDL 等 GPU 云服务器）</span></span>
<span class="line"><span style="color:#A6ACCD;">pip install unsloth torch transformers trl peft datasets</span></span>
<span class="line"><span style="color:#A6ACCD;">pip install pandas pillow openpyxl  </span><span style="color:#676E95;"># VL 微调额外依赖</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;"># 模型路径（脚本内为 AutoDL 云服务器路径，本地需修改）</span></span>
<span class="line"><span style="color:#676E95;"># /root/autodl-tmp/models/Qwen/Qwen2.5-7B-Instruct</span></span>
<span class="line"><span style="color:#676E95;"># /root/autodl-tmp/datasets/gsm8k</span></span>
<span class="line"></span></code></pre></div><p><strong>代码示例</strong></p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki"><code><span class="line"><span style="color:#676E95;"># 加载 LoRA 微调后的医疗模型推理</span></span>
<span class="line"><span style="color:#89DDFF;">from</span><span style="color:#A6ACCD;"> unsloth </span><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> FastLanguageModel</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">model</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> tokenizer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">from_pretrained</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lora_model_medical</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;">    </span><span style="color:#676E95;"># 微调保存的路径</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;">max_seq_length</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">2048</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;">load_in_4bit</span><span style="color:#89DDFF;">=True,</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">for_inference</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;"># 开启 2x 推理加速</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">inputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">tokenizer</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">medical_prompt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">format</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">请问高血压的饮食注意事项有哪些？</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">)],</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;">return_tensors</span><span style="color:#89DDFF;">=</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">pt</span><span style="color:#89DDFF;">&quot;</span></span>
<span class="line"><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">to</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">cuda</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">outputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">generate</span><span style="color:#89DDFF;">(**</span><span style="color:#82AAFF;">inputs</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;">max_new_tokens</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">256</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">tokenizer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">decode</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">outputs</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">]))</span></span>
<span class="line"></span></code></pre></div><p><strong>常见问题</strong></p><ul><li><strong><code>CUDA out of memory</code></strong>：减小 <code>per_device_train_batch_size</code> 至 1，增大 <code>gradient_accumulation_steps</code> 到 8；或将 <code>r</code> 从 16 降至 8。</li><li><strong>路径找不到</strong>：脚本中路径为 AutoDL 云服务器路径（<code>/root/autodl-tmp/...</code>），本地运行需全部改为本地路径。</li><li><strong>GRPO 训练不稳定</strong>：<code>num_generations=6</code> 在显存不足时可降为 4；<code>max_steps=250</code> 可先用 50 步验证奖励曲线是否上升。</li></ul><hr><h2 id="第五部分-优缺点评估与未来展望" tabindex="-1">第五部分：优缺点评估与未来展望 <a class="header-anchor" href="#第五部分-优缺点评估与未来展望" aria-hidden="true">#</a></h2><p><strong>优势</strong></p><ul><li>Unsloth 框架加速显著，同等显存下可训练更大批量或更多步</li><li>QLoRA（4bit + LoRA）让消费级 GPU 可训练 7B 模型，极大降低微调门槛</li><li>涵盖三种微调范式（SFT/多模态 SFT/GRPO），覆盖主流场景</li><li><code>image_svd</code> + <code>ALS</code> 提供了理解 LoRA 数学直觉的可视化辅助</li></ul><p><strong>已知局限</strong></p><ul><li>脚本路径硬编码为 AutoDL 服务器路径，不适合直接在本地运行</li><li>训练脚本与主服务完全解耦——微调后的模型无法直接注入到 <code>chat.py</code> 或 <code>rag.py</code> 的推理流程</li><li>缺少训练指标可视化（TensorBoard/WandB 集成）</li><li>医疗/法律场景的微调模型尚未集成到主服务中</li></ul><p><strong>演进建议</strong></p><ul><li>短期：将路径改为环境变量配置，支持本地 + AutoDL 两套环境；添加 WandB 训练指标追踪</li><li>中期：将微调后的 LoRA 模型通过 Ollama 格式（GGUF）导出，无缝集成到 <code>ollama_chat.py</code> 的 <code>DEFAULT_MODEL</code> 中</li><li>长期：构建微调流水线：数据上传 → 自动数据清洗 → 触发训练（AutoDL API） → 模型自动部署 → A/B 测试对比基座模型</li></ul><p><strong>行业前沿</strong></p><ul><li><strong>DoRA（权重分解 LoRA）</strong>：将权重分解为幅度和方向两部分分别训练，比标准 LoRA 效果更好，Unsloth 已支持</li><li><strong>ORPO（偏好优化 LoRA）</strong>：SFT 和偏好对齐（RLHF）一步完成，比 GRPO 更简单</li><li><strong>LoRA+ 和 Flora</strong>：改进 LoRA 的优化器学习率策略，在相同参数量下收敛更快、效果更好</li><li><strong>持续预训练（Continual Pretraining）</strong>：在领域语料（医学文献、法律条文）上做预训练再 SFT，比纯 SFT 的领域理解更深，是专业模型的终极方案</li></ul></div></div></main><!--[--><!--]--><!----><!--[--><!--]--></div></div></div></div></div><footer class="VPFooter" data-v-9c83c81e data-v-0bba5d65><div class="container" data-v-0bba5d65><p class="message" data-v-0bba5d65>技术文档集合</p><p class="copyright" data-v-0bba5d65>Copyright © 2024</p></div></footer><!--[--><!--]--></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"ai_base_aigc.md\":\"b06d22d5\",\"ai_base_coze_dify.md\":\"6bc6dd6c\",\"ai_base_ddg_serpapi.md\":\"241d3154\",\"ai_base_dashscope_modelscope.md\":\"6825092f\",\"ai_base_faiss.md\":\"871abb2b\",\"ai_base_gpt.md\":\"c9920aec\",\"ai_base_langchain.md\":\"9fb6c5a0\",\"ai_base_lcel.md\":\"3f936c89\",\"ai_base_models.md\":\"730367d9\",\"ai_base_moe.md\":\"f09f47bc\",\"ai_base_nlp.md\":\"60d3440d\",\"ai_base_qianwen_vl.md\":\"9314fcad\",\"ai_base_rag.md\":\"552e1732\",\"ai_base_transformer.md\":\"eb25d0fc\",\"ai_base_word2vec.md\":\"5861e115\",\"ai_base_大模型应用开发模式.md\":\"5663d7dd\",\"ai_base_智能体设计模式.md\":\"8722b638\",\"ai_base_稠密向量-稀疏向量.md\":\"9f31615f\",\"ai_home_01_vector_db.md\":\"87f2fcff\",\"ai_home_02_rag.md\":\"e6654b41\",\"ai_home_03_knowledge_base.md\":\"bd237aea\",\"ai_home_04_agent.md\":\"635a9aad\",\"ai_home_05_a2a.md\":\"aaaac254\",\"ai_home_06_mcp.md\":\"5fd035ac\",\"ai_home_07_chat.md\":\"92bf0ab2\",\"ai_home_08_tools.md\":\"04e23e0d\",\"ai_home_09_finetuning.md\":\"224b6c0b\",\"ai_home_readme.md\":\"374380ee\",\"algorithm_1.两数之和.md\":\"9ecc0cac\",\"algorithm_10.正则表达式匹配.md\":\"1e6536ee\",\"algorithm_100.相同的树.md\":\"bf987390\",\"algorithm_1005.k-次取反后最大化的数组和.md\":\"adff5c12\",\"algorithm_101.对称二叉树.md\":\"0b795ee3\",\"algorithm_1019.链表中的下一个更大节点.md\":\"d97a048d\",\"algorithm_102.二叉树的层序遍历.md\":\"dc9a0dac\",\"algorithm_103.二叉树的锯齿形层序遍历.md\":\"53d9f321\",\"algorithm_104.二叉树的最大深度.md\":\"263b6ddb\",\"algorithm_105.从前序与中序遍历序列构造二叉树.md\":\"08c0951f\",\"algorithm_106.从中序与后序遍历序列构造二叉树.md\":\"51f493a0\",\"algorithm_107.二叉树的层序遍历-ii.md\":\"9e3abc70\",\"algorithm_108.将有序数组转换为二叉搜索树.md\":\"84bee126\",\"algorithm_109.有序链表转换二叉搜索树.md\":\"ba8f30bb\",\"algorithm_11.盛最多水的容器.md\":\"ba12d9d5\",\"algorithm_110.平衡二叉树.md\":\"3e30ca9a\",\"algorithm_111.二叉树的最小深度.md\":\"4f40de1a\",\"algorithm_112.路径总和.md\":\"9a7425d6\",\"algorithm_1122.数组的相对排序.md\":\"8ecbfc1d\",\"algorithm_113.路径总和-ii.md\":\"e72a09c5\",\"algorithm_114.二叉树展开为链表.md\":\"66c9c48d\",\"algorithm_118.杨辉三角.md\":\"7182bb21\",\"algorithm_1189.气球-的最大数量.md\":\"51d400fe\",\"algorithm_120.三角形最小路径和.md\":\"b61cd45f\",\"algorithm_1201.丑数-iii.md\":\"1c66e4cc\",\"algorithm_1207.独一无二的出现次数.md\":\"f74d693c\",\"algorithm_121.买卖股票的最佳时机.md\":\"6c3b8bc2\",\"algorithm_122.买卖股票的最佳时机-ii.md\":\"6aea2c60\",\"algorithm_123.买卖股票的最佳时机-iii.md\":\"a825cda0\",\"algorithm_125.验证回文串.md\":\"7f1a1423\",\"algorithm_128.最长连续序列.md\":\"4c2dd5f8\",\"algorithm_129.求根节点到叶节点数字之和.md\":\"9739f8a8\",\"algorithm_13.罗马数字转整数.md\":\"f1217653\",\"algorithm_131.分割回文串.md\":\"c46a13cf\",\"algorithm_132.分割回文串-ii.md\":\"f8784223\",\"algorithm_1323.6-和-9-组成的最大数字.md\":\"a3d91e15\",\"algorithm_134.加油站.md\":\"f412225d\",\"algorithm_1346.检查整数及其两倍数是否存在.md\":\"6f3d9e5a\",\"algorithm_136.只出现一次的数字.md\":\"5968c202\",\"algorithm_1370.上升下降字符串.md\":\"4cc1bdea\",\"algorithm_138.复制带随机指针的链表.md\":\"d053d6cb\",\"algorithm_14.最长公共前缀.md\":\"64f2f480\",\"algorithm_141.环形链表.md\":\"af20c5fb\",\"algorithm_142.环形链表-ii.md\":\"1ab46568\",\"algorithm_143.重排链表.md\":\"2f2d8b7b\",\"algorithm_144.二叉树的前序遍历.md\":\"9cd0ce83\",\"algorithm_145.二叉树的后序遍历.md\":\"f1d2f0cc\",\"algorithm_146.lru-缓存机制.md\":\"94da4dce\",\"algorithm_147.对链表进行插入排序.md\":\"dfdd6214\",\"algorithm_1471.数组中的-k-个最强值.md\":\"3b4b0e30\",\"algorithm_1472.设计浏览器历史记录.md\":\"38474b98\",\"algorithm_148.排序链表.md\":\"61b47742\",\"algorithm_15.三数之和.md\":\"4a87a46d\",\"algorithm_151.反转字符串中的单词.md\":\"47f86157\",\"algorithm_152.乘积最大子数组.md\":\"adc6970a\",\"algorithm_153.寻找旋转排序数组中的最小值.md\":\"dd55f97f\",\"algorithm_155.最小栈.md\":\"f427cbef\",\"algorithm_16.最接近的��数之和.md\":\"d2a767bb\",\"algorithm_160.相交链表.md\":\"29b4e21a\",\"algorithm_162.寻找峰值.md\":\"dc69822d\",\"algorithm_164.最大间距.md\":\"57575b05\",\"algorithm_1669.合并两个链表.md\":\"e0c3ead5\",\"algorithm_167.两数之和-ii-输入有序数组.md\":\"5be55411\",\"algorithm_1684.统计一致字符串的数目.md\":\"dfe7964c\",\"algorithm_169.多数元素.md\":\"d86655bb\",\"algorithm_17.电话号码的字母组合.md\":\"d0739c83\",\"algorithm_171.excel-表列序号.md\":\"78b624b4\",\"algorithm_172.阶乘后的零.md\":\"e49ca5db\",\"algorithm_1721.交换链表中的节点.md\":\"42d58816\",\"algorithm_1748.唯一元素的和.md\":\"b746833b\",\"algorithm_1768.交替合并字符串.md\":\"2bf170a4\",\"algorithm_179.最大数.md\":\"4b0703d0\",\"algorithm_18.四数之和.md\":\"1009efa7\",\"algorithm_187.重复的dna序列.md\":\"f8f87417\",\"algorithm_188.买卖股票的最佳时机-iv.md\":\"63c8f330\",\"algorithm_189.旋转数组.md\":\"8669463e\",\"algorithm_19.删除链表的倒数第-n-个结点.md\":\"e419cf1f\",\"algorithm_193.有效电话号码.md\":\"de6221d2\",\"algorithm_198.打家劫舍.md\":\"266af7b0\",\"algorithm_2.两数相加.md\":\"2c6c56a6\",\"algorithm_20.有效的括号.md\":\"cfdfe036\",\"algorithm_200.岛屿数量.md\":\"75388249\",\"algorithm_202.快乐数.md\":\"b9448596\",\"algorithm_203.移除链表元素.md\":\"ff317acf\",\"algorithm_205.同构字符串.md\":\"9194b477\",\"algorithm_206.反转链表.md\":\"21bb212a\",\"algorithm_209.长度最小的子数组.md\":\"79add931\",\"algorithm_2095.删除链表的中间节点.md\":\"55c7b786\",\"algorithm_21.合并两个有序链表.md\":\"537e16d1\",\"algorithm_2130.链表最大孪生和.md\":\"3ec5ad08\",\"algorithm_215.数组中的第k个最大元素.md\":\"a2aba6ae\",\"algorithm_216.组合总和-iii.md\":\"b5e1a1d7\",\"algorithm_217.存在重复元素.md\":\"9c2ff234\",\"algorithm_2181.合并零之间的节点.md\":\"4488cedd\",\"algorithm_219.存在重复元素-ii.md\":\"85f838bc\",\"algorithm_22.括号生成.md\":\"6a45299c\",\"algorithm_222.完全二叉树的节点个数.md\":\"b7a9d070\",\"algorithm_225.用队列实现栈.md\":\"8eaef0e6\",\"algorithm_226.翻转二叉树.md\":\"cc859337\",\"algorithm_23.合并k个升序链表.md\":\"cb28a2f9\",\"algorithm_230.二叉搜索树中第k小的元素.md\":\"22b266ca\",\"algorithm_231.2-的幂.md\":\"58089fa5\",\"algorithm_232.用栈实现队列.md\":\"173aefca\",\"algorithm_234.回文链表.md\":\"5605b8a3\",\"algorithm_235.二叉搜索树的最近公共祖先.md\":\"2a6721f9\",\"algorithm_236.二叉树的最近公共祖先.md\":\"b0d1648e\",\"algorithm_237.删除链表中的节点.md\":\"843c3b29\",\"algorithm_238.除自身以外数组的乘积.md\":\"696392b9\",\"algorithm_24.两两交换链表中的节点.md\":\"95ecb982\",\"algorithm_240.搜索二维矩阵-ii.md\":\"2cec6208\",\"algorithm_242.有效的字母异位词.md\":\"7a0d1765\",\"algorithm_2487.从链表中移除节点.md\":\"11cff899\",\"algorithm_25.k-个一组翻转链表.md\":\"06fdeb4d\",\"algorithm_257.二叉树的所有路径.md\":\"b805273e\",\"algorithm_258.各位相加.md\":\"40b95a26\",\"algorithm_26.删除排序数组中的重复项.md\":\"a1df229d\",\"algorithm_263.丑数.md\":\"c43eb2b0\",\"algorithm_264.丑数-ii.md\":\"bd325359\",\"algorithm_268.丢失的数字.md\":\"f074ca33\",\"algorithm_27.移除元素.md\":\"c1a5711c\",\"algorithm_274.h-指数.md\":\"a00e1899\",\"algorithm_278.第一个错误的版本.md\":\"59a8ca72\",\"algorithm_28.实现-str-str.md\":\"61d52a86\",\"algorithm_283.移动零.md\":\"bc8e9df3\",\"algorithm_290.单词规律.md\":\"f7adebf9\",\"algorithm_3.无重复字符的最长子串.md\":\"9f8fe163\",\"algorithm_300.最长递增子序列.md\":\"7e5f9fa4\",\"algorithm_306.累加数.md\":\"d4b82d78\",\"algorithm_309.最佳买卖股票时机含冷冻期.md\":\"ebcc4b44\",\"algorithm_313.超级丑数.md\":\"b1b60e40\",\"algorithm_32.最长有效括号.md\":\"172a3e07\",\"algorithm_322.零钱兑换.md\":\"3bafdd54\",\"algorithm_326.3-的幂.md\":\"cb395aaf\",\"algorithm_328.奇偶链表.md\":\"963896bd\",\"algorithm_33.搜索旋转排序数组.md\":\"0731921f\",\"algorithm_34.在排序数组中查找元素的第一个和最后一个位置.md\":\"254830c7\",\"algorithm_342.4-的幂.md\":\"18a623ab\",\"algorithm_344.反转字符串.md\":\"c4cb4cfd\",\"algorithm_347.前-k-个高频元素.md\":\"30aa8067\",\"algorithm_349.两个数组的交集.md\":\"0ea53558\",\"algorithm_35.搜索插入位置.md\":\"1698a9e5\",\"algorithm_350.两个数组的交集-ii.md\":\"c314517f\",\"algorithm_357.计算各个位数不同的数字个数.md\":\"f2091af6\",\"algorithm_36.有效的数独.md\":\"c0f98a5a\",\"algorithm_37.解数独.md\":\"2cf2c610\",\"algorithm_373.查找和最小的k对数字.md\":\"645a671c\",\"algorithm_374.猜数字大小.md\":\"4e2390d5\",\"algorithm_378.有序矩阵中第-k-小的元素.md\":\"ed7f8a2a\",\"algorithm_380.o-1-时间插入、删除和获取随机元素.md\":\"985dcfa4\",\"algorithm_381.o-1-时间插入、删除和获取随机元素-允许重复.md\":\"6d61d03c\",\"algorithm_383.赎金信.md\":\"8e4d4a71\",\"algorithm_384.打乱数组.md\":\"7e3d84d8\",\"algorithm_387.字符串中的第一个唯一字符.md\":\"4ae4fc29\",\"algorithm_389.找不同.md\":\"f74d9541\",\"algorithm_39.组合总和.md\":\"9a144959\",\"algorithm_392.判断子序列.md\":\"33305fa9\",\"algorithm_398.随机数索引.md\":\"ee23a02f\",\"algorithm_40.组合总和-ii.md\":\"c1405b7b\",\"algorithm_404.左叶子之和.md\":\"417cdd73\",\"algorithm_409.最长回文串.md\":\"aa44d6c8\",\"algorithm_41.缺失的第一个正数.md\":\"d157ded2\",\"algorithm_414.第三大的数.md\":\"54694840\",\"algorithm_42.接雨水.md\":\"c4150183\",\"algorithm_423.从英文中重建数字.md\":\"03294d93\",\"algorithm_429.n-叉树的层序遍历.md\":\"e6cc02a1\",\"algorithm_43.字符串相乘.md\":\"8d7ed325\",\"algorithm_430.扁平化多级双向链表.md\":\"60c3c6c3\",\"algorithm_432.全-o-1-的数据结构.md\":\"d96ed440\",\"algorithm_441.排列硬币.md\":\"32939553\",\"algorithm_442.数组中重复的数据.md\":\"c9414ce2\",\"algorithm_445.两数相加-ii.md\":\"0dd96cf8\",\"algorithm_450.删除二叉搜索树中的节点.md\":\"8ed3afaa\",\"algorithm_451.根据字符出现频率排序.md\":\"b73904f7\",\"algorithm_455.分发饼干.md\":\"c35ca636\",\"algorithm_459.重复的子字符串.md\":\"149da802\",\"algorithm_46.全排列.md\":\"e1e4d9f5\",\"algorithm_47.全排列-ii.md\":\"c5867a73\",\"algorithm_496.下一个更大元素-i.md\":\"79b98fa5\",\"algorithm_5.最长回文子串.md\":\"85c0e542\",\"algorithm_50.pow-x-n.md\":\"d4f80cb9\",\"algorithm_500.键盘行.md\":\"8440418e\",\"algorithm_503.下一个更大元素-ii.md\":\"73dfbf50\",\"algorithm_509.斐波那契数.md\":\"af58811b\",\"algorithm_51.n-皇后.md\":\"8489145b\",\"algorithm_513.找树左下角的值.md\":\"4a36090d\",\"algorithm_515.在每个树行中找最大值.md\":\"343761fe\",\"algorithm_52.n皇后-ii.md\":\"04cf341a\",\"algorithm_526.优美的排列.md\":\"f3c4cec9\",\"algorithm_53.最大子数组和.md\":\"cf7d367e\",\"algorithm_530.二叉搜索树的最小绝对差.md\":\"60d0f666\",\"algorithm_54.螺旋矩阵.md\":\"77b28531\",\"algorithm_55.跳跃游戏.md\":\"2e35f321\",\"algorithm_557.反转字符串中的单词-iii.md\":\"2fbc8f74\",\"algorithm_56.合并区间.md\":\"7f17102c\",\"algorithm_561.数组拆分-i.md\":\"f6d2f37a\",\"algorithm_567.字符串的排列.md\":\"5b9a9573\",\"algorithm_575.分糖果.md\":\"fafd5549\",\"algorithm_58.最后一个单词的长度.md\":\"a328b0e7\",\"algorithm_589.n-叉树的前序遍历.md\":\"1d2a22e0\",\"algorithm_59.螺旋矩阵-ii.md\":\"0e0d0f20\",\"algorithm_590.n-叉树的后序遍历.md\":\"027d10b5\",\"algorithm_599.两个列表的最小索引总和.md\":\"22c706f9\",\"algorithm_60.排列序列.md\":\"f45c72ea\",\"algorithm_605.种花问题.md\":\"22244b02\",\"algorithm_61.旋转链表.md\":\"d21e1e03\",\"algorithm_617.合并二叉树.md\":\"02bab98c\",\"algorithm_62.不同路径.md\":\"71f0373c\",\"algorithm_622.设计循环队列.md\":\"dbb648eb\",\"algorithm_629.k个逆序对数组.md\":\"be8c7c1e\",\"algorithm_637.二叉树的层平均值.md\":\"6296d539\",\"algorithm_64.最小路径和.md\":\"dcbc91c0\",\"algorithm_645.错误的集合.md\":\"75ac25b4\",\"algorithm_647.回文子串.md\":\"98e2971a\",\"algorithm_66.加一.md\":\"61ffe7f7\",\"algorithm_662.二叉树最大宽度.md\":\"4e972400\",\"algorithm_668.乘法表中第k小的数.md\":\"d6567cf4\",\"algorithm_67.二进制求和.md\":\"906dce62\",\"algorithm_673.最长递增子序列的个数.md\":\"41d079ad\",\"algorithm_674.最长连续递增序列.md\":\"2b333c68\",\"algorithm_680.验证回文字符串-ⅱ.md\":\"9e232b28\",\"algorithm_682.棒球比赛.md\":\"85a94b40\",\"algorithm_69.sqrt-x.md\":\"b08bfde4\",\"algorithm_696.计数二进制子串.md\":\"e86bd8c4\",\"algorithm_697.数组的度.md\":\"a18925e2\",\"algorithm_7.整数反转.md\":\"b6465f52\",\"algorithm_70.爬楼梯.md\":\"cf3869ac\",\"algorithm_703.数据流中的第-k-大元素.md\":\"5bd0796c\",\"algorithm_704.二分查找.md\":\"71aec649\",\"algorithm_707.设计链表.md\":\"f2e76888\",\"algorithm_71.简化路径.md\":\"71a575ef\",\"algorithm_713.乘积小于k的子数组.md\":\"bbc5996e\",\"algorithm_714.买卖股票的最佳时机含手续费.md\":\"d2f3967b\",\"algorithm_719.找出第-k-小的距离对.md\":\"92046e41\",\"algorithm_72.编辑距离.md\":\"412c3d9e\",\"algorithm_725.分隔链表.md\":\"add59e8d\",\"algorithm_739.每日温度.md\":\"22817611\",\"algorithm_74.搜索二维矩阵.md\":\"e89f3383\",\"algorithm_766.托普利茨矩阵.md\":\"8406160a\",\"algorithm_77.组合.md\":\"86d5f274\",\"algorithm_771.宝石与石头.md\":\"bbfaa526\",\"algorithm_78.子集.md\":\"215049cb\",\"algorithm_783.二叉搜索树节点最小距离.md\":\"ec5d5a61\",\"algorithm_786.第-k-个最小的素数分数.md\":\"7cd47c3c\",\"algorithm_79.单词搜索.md\":\"b978da4d\",\"algorithm_80.删除有序数组中的重复项-ii.md\":\"ecb207e0\",\"algorithm_81.搜索旋转排序数组-ii.md\":\"e3a82062\",\"algorithm_819.最常见的单词.md\":\"ddaec2d1\",\"algorithm_82.删除排序链表中的重复元素-ii.md\":\"051b38b0\",\"algorithm_83.删除排序链表中的重复元素.md\":\"f09c9944\",\"algorithm_85.最大矩形.md\":\"b544ff92\",\"algorithm_852.山脉数组的峰顶索引.md\":\"9ac5f3c6\",\"algorithm_86.分隔链表.md\":\"8d303484\",\"algorithm_860.柠檬水找零.md\":\"1cee7dce\",\"algorithm_876.链表的中间节点.md\":\"d4c8ea63\",\"algorithm_88.合并两个有序数组.md\":\"84eab9ce\",\"algorithm_884.两句话中的不常见单词.md\":\"4f1d4bf5\",\"algorithm_9.回文数.md\":\"eec8d896\",\"algorithm_90.子集-ii.md\":\"0034dc60\",\"algorithm_901.股票价格跨度.md\":\"00a4b0a2\",\"algorithm_908.最小差值-i.md\":\"2a9e1f5e\",\"algorithm_912.排序数组.md\":\"e22c0a3a\",\"algorithm_914.卡牌分组.md\":\"ccfe9953\",\"algorithm_92.反转链表-ii.md\":\"5dbe1533\",\"algorithm_922.按奇偶排序数组-ii.md\":\"b7b18ced\",\"algorithm_929.独特的电子邮件地址.md\":\"41102e6b\",\"algorithm_93.复原-ip-地址.md\":\"5efea982\",\"algorithm_94.二叉树的中序遍历.md\":\"c66a8793\",\"algorithm_942.增减字符串匹配.md\":\"99a7566b\",\"algorithm_95.不同的二叉搜索树-ii.md\":\"7c345b10\",\"algorithm_953.验证外星语词典.md\":\"32e5031e\",\"algorithm_96.不同的二叉搜索树.md\":\"3b4ad8ee\",\"algorithm_961.在长度-2-n-的数组中找出重复-n-次的元素.md\":\"2d8fa06a\",\"algorithm_976.三角形的最大周长.md\":\"c6377d96\",\"algorithm_98.验证二叉搜索树.md\":\"1f52410e\",\"algorithm_99.恢复二叉搜索树.md\":\"d6ee57b3\",\"algorithm_readme.md\":\"fc7c697c\",\"backend_acid.md\":\"40b9d98f\",\"backend_acid_my.md\":\"7778a6d3\",\"backend_python gil 影响与解决方案.md\":\"b19806a2\",\"backend_restfulapi.md\":\"8e191874\",\"backend_database_basis.md\":\"54b45f1c\",\"backend_database_character-set.md\":\"3e7770e0\",\"backend_database_nosql.md\":\"76b2ce6e\",\"backend_database_redis_redis-questions-01.md\":\"696628d9\",\"backend_database_redis_redis-questions-02.md\":\"c26bb98b\",\"backend_database_redis_数据结构.md\":\"3d1e0c83\",\"backend_database_sql_sql-syntax-summary.md\":\"db8fe25d\",\"backend_docker_docker-in-action.md\":\"cbf88c95\",\"backend_docker_docker-intro.md\":\"07001e99\",\"backend_index.md\":\"c7409a90\",\"backend_分库分表策略.md\":\"0a68628d\",\"backend_协程.md\":\"f3eb6e75\",\"backend_死锁.md\":\"c5a3a6e4\",\"backend_进程-线程-协程.md\":\"1a55cd36\",\"index.md\":\"d9390ea0\"}")</script>
    <script type="module" async src="/assets/app.bf2af4c6.js"></script>
    
  </body>
</html>