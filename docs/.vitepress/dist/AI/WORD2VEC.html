<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>技术文档 | 技术文档</title>
    <meta name="description" content="技术学习文档集合">
    <link rel="stylesheet" href="/assets/style.db59e0d6.css">
    <link rel="modulepreload" href="/assets/app.23d277bf.js">
    <link rel="modulepreload" href="/assets/AI_WORD2VEC.md.0edbca57.lean.js">
    
    <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-9c83c81e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-be9c27de></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-be9c27de> Skip to content </a><!--]--><!----><header class="VPNav" data-v-9c83c81e data-v-bd98ce1b><div class="VPNavBar has-sidebar" data-v-bd98ce1b data-v-be850364><div class="container" data-v-be850364><div class="VPNavBarTitle has-sidebar" data-v-be850364 data-v-ef6bdfee><a class="title" href="/" data-v-ef6bdfee><!--[--><!--]--><!----><!--[-->技术文档<!--]--><!--[--><!--]--></a></div><div class="content" data-v-be850364><!--[--><!--]--><!----><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-be850364 data-v-4f0f7d90><span id="main-nav-aria-label" class="visually-hidden" data-v-4f0f7d90>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" data-v-4f0f7d90 data-v-d1df1d79 data-v-cbb71e82><!--[-->首页<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/AI/AIGC.html" data-v-4f0f7d90 data-v-d1df1d79 data-v-cbb71e82><!--[-->文档<!--]--><!----></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-be850364 data-v-6975dfb0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-6975dfb0 data-v-a11464a8 data-v-9b61e15c><span class="check" data-v-9b61e15c><span class="icon" data-v-9b61e15c><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-a11464a8><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-a11464a8><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-be850364 data-v-9d62d057 data-v-2aee37ba><!--[--><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-be850364 data-v-af83da42 data-v-0bf5642f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-0bf5642f><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-0bf5642f><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-0bf5642f><div class="VPMenu" data-v-0bf5642f data-v-958884f0><!----><!--[--><!--[--><!----><div class="group" data-v-af83da42><div class="item appearance" data-v-af83da42><p class="label" data-v-af83da42>Appearance</p><div class="appearance-action" data-v-af83da42><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-af83da42 data-v-a11464a8 data-v-9b61e15c><span class="check" data-v-9b61e15c><span class="icon" data-v-9b61e15c><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-a11464a8><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-a11464a8><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-af83da42><div class="item social-links" data-v-af83da42><div class="VPSocialLinks social-links-list" data-v-af83da42 data-v-2aee37ba><!--[--><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-be850364 data-v-cd76eed2><span class="container" data-v-cd76eed2><span class="top" data-v-cd76eed2></span><span class="middle" data-v-cd76eed2></span><span class="bottom" data-v-cd76eed2></span></span></button></div></div></div><!----></header><div class="VPLocalNav" data-v-9c83c81e data-v-05a75127><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-05a75127><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-05a75127><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-05a75127>Menu</span></button><a class="top-link" href="#" data-v-05a75127> Return to top </a></div><aside class="VPSidebar" data-v-9c83c81e data-v-66069f15><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-66069f15><span class="visually-hidden" id="sidebar-aria-label" data-v-66069f15> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-66069f15><section class="VPSidebarGroup" data-v-66069f15 data-v-7785691c><div class="title" data-v-7785691c><h2 class="title-text" data-v-7785691c>AI</h2><div class="action" data-v-7785691c><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="icon minus" data-v-7785691c><path d="M19,2H5C3.3,2,2,3.3,2,5v14c0,1.7,1.3,3,3,3h14c1.7,0,3-1.3,3-3V5C22,3.3,20.7,2,19,2zM20,19c0,0.6-0.4,1-1,1H5c-0.6,0-1-0.4-1-1V5c0-0.6,0.4-1,1-1h14c0.6,0,1,0.4,1,1V19z"></path><path d="M16,11H8c-0.6,0-1,0.4-1,1s0.4,1,1,1h8c0.6,0,1-0.4,1-1S16.6,11,16,11z"></path></svg><svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="icon plus" data-v-7785691c><path d="M19,2H5C3.3,2,2,3.3,2,5v14c0,1.7,1.3,3,3,3h14c1.7,0,3-1.3,3-3V5C22,3.3,20.7,2,19,2z M20,19c0,0.6-0.4,1-1,1H5c-0.6,0-1-0.4-1-1V5c0-0.6,0.4-1,1-1h14c0.6,0,1,0.4,1,1V19z"></path><path d="M16,11h-3V8c0-0.6-0.4-1-1-1s-1,0.4-1,1v3H8c-0.6,0-1,0.4-1,1s0.4,1,1,1h3v3c0,0.6,0.4,1,1,1s1-0.4,1-1v-3h3c0.6,0,1-0.4,1-1S16.6,11,16,11z"></path></svg></div></div><div class="items" data-v-7785691c><!--[--><!--[--><a class="VPLink link link" href="/AI/AIGC.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>AIGC</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/COZE_DIFY.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>COZE & DIFY</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/DashScope_ModelScope.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>DashScope & ModelScope</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/DDG_SERPAPI.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>DDG & SERPAPI</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/FAISS.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>FAISS</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/GPT%E6%9E%B6%E6%9E%84.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>GPT架构</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/LANGCHAIN.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>LANGCHAIN</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/LCEL.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>LCEL</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/MODELS.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>MODELS</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/MOE.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>MOE</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/NLP.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>NLP</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/QIANWEN_VL.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>QIANWEN VL</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/SERPAPI.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>SERPAPI</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link active" href="/AI/WORD2VEC.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>WORD2VEC</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>大模型应用开发模式</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>智能体系统设计</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/%E7%A8%A0%E5%AF%86%E5%90%91%E9%87%8F-%E7%A8%80%E7%96%8F%E5%90%91%E9%87%8F.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>稠密向量-稀疏向量</span><!--]--><!----></a><!----><!--]--><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-9c83c81e data-v-954ad629><div class="VPDoc has-sidebar has-aside" data-v-954ad629 data-v-dc19973f><div class="container" data-v-dc19973f><div class="aside" data-v-dc19973f><div class="aside-curtain" data-v-dc19973f></div><div class="aside-container" data-v-dc19973f><div class="aside-content" data-v-dc19973f><div class="VPDocAside" data-v-dc19973f data-v-63938968><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" data-v-63938968 data-v-72b1abc9><div class="content" data-v-72b1abc9><div class="outline-marker" data-v-72b1abc9></div><div class="outline-title" data-v-72b1abc9>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-72b1abc9><span class="visually-hidden" id="doc-outline-aria-label" data-v-72b1abc9> Table of Contents for current page </span><ul class="root" data-v-72b1abc9 data-v-a950ca15><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-63938968></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-dc19973f><div class="content-container" data-v-dc19973f><!--[--><!--]--><main class="main" data-v-dc19973f><div style="position:relative;" class="vp-doc _AI_WORD2VEC" data-v-dc19973f><div><h3 id="一、什么是-word2vec" tabindex="-1">一、什么是 Word2Vec？ <a class="header-anchor" href="#一、什么是-word2vec" aria-hidden="true">#</a></h3><p><strong>Word2Vec</strong> 并不是一个单一的算法，而是一个在 2013 由 Google 的 Tomas Mikolov 等人提出的一系列<strong>模型和工具</strong>。它的核心思想是：<strong>将一个词语映射到一个高维的向量空间中，并且让语义上相似的词语在这个空间中的向量位置也彼此接近。</strong></p><p>简单来说，Word2Vec 的核心理念是： <strong>“一个单词的含义，可以由它周围经常出现的单词（上下文）来定义。”</strong> 这被称为 <strong>分布假说</strong>。</p><ul><li><strong>输入</strong>：大量的文本数据。</li><li><strong>输出</strong>：一个“词向量模型”。在这个模型中，每个单词都被表示成一个固定长度的向量（比如300维）。</li><li><strong>目标</strong>：语义相似的词，其向量的<strong>余弦相似度</strong>很高（即方向接近）；同时，词向量还能捕捉到复杂的语义关系。</li></ul><hr><h3 id="二、核心模型-两种训练方式" tabindex="-1">二、核心模型：两种训练方式 <a class="header-anchor" href="#二、核心模型-两种训练方式" aria-hidden="true">#</a></h3><p>Word2Vec 提供了两种主要的模型架构来实现上述思想，它们都使用简单的神经网络，但训练任务不同。</p><h4 id="_1-cbow-连续词袋模型" tabindex="-1">1. CBOW（连续词袋模型） <a class="header-anchor" href="#_1-cbow-连续词袋模型" aria-hidden="true">#</a></h4><ul><li><strong>目标</strong>：<strong>通过上下文来预测中心词</strong>。</li><li><strong>工作原理</strong>：模型将目标词语周围的所有上下文词语（例如，前后各2个词）的向量求和或平均，然后尝试预测中间的那个目标词语。</li><li><strong>比喻</strong>：给你一段话中挖掉的一个空，让你根据空周围的词来猜这个空应该填什么词。</li><li><strong>特点</strong>：训练速度快，对高频词更准确。</li></ul><h4 id="_2-skip-gram-跳字模型" tabindex="-1">2. Skip-gram（跳字模型） <a class="header-anchor" href="#_2-skip-gram-跳字模型" aria-hidden="true">#</a></h4><ul><li><strong>目标</strong>：<strong>通过中心词来预测其上下文</strong>。</li><li><strong>工作原理</strong>：给定一个中心词语，模型尝试预测它周围一定窗口大小内的所有上下文词语。</li><li><strong>比喻</strong>：给你一个关键词，让你写出它周围可能出现的词。</li><li><strong>特点</strong>：在小型数据集上表现更好，尤其能很好地处理低频词。</li></ul><p><strong>简单对比：</strong></p><ul><li><strong>CBOW</strong>: <code>上下文 -&gt; 中心词</code></li><li><strong>Skip-gram</strong>: <code>中心词 -&gt; 上下文</code></li></ul><p>在实践中，<strong>Skip-gram 模型通常能产生质量更高的词向量</strong>，尤其是在捕捉复杂的语义关系方面，因此更为常用。</p><hr><h3 id="三、一个详细的-skip-gram-例子" tabindex="-1">三、一个详细的 Skip-gram 例子 <a class="header-anchor" href="#三、一个详细的-skip-gram-例子" aria-hidden="true">#</a></h3><p>假设我们有一个非常简单的句子，并且设定窗口大小为2：</p><blockquote><p>“The quick brown fox jumps.”</p></blockquote><p><strong>1. 创建训练样本：</strong> 我们以中心词 <code>brown</code> 为例，它的上下文（窗口为2）是 <code>[The, quick, fox, jumps]</code>。Skip-gram 会生成以下（输入，输出）训练对：</p><ul><li>(brown, The)</li><li>(brown, quick)</li><li>(brown, fox)</li><li>(brown, jumps)</li></ul><p>对整个语料库中的每一个词都进行这样的操作，我们会得到数百万甚至数十亿个这样的训练对。</p><p><strong>2. 模型结构（简化）：</strong></p><ul><li><strong>输入层</strong>：一个大小为 <code>V</code> 的 one-hot 向量，其中 <code>V</code> 是词汇表的大小。例如，如果我们的词汇表是 <code>[The, quick, brown, fox, jumps]</code>，那么 <code>brown</code> 的 one-hot 向量就是 <code>[0, 0, 1, 0, 0]</code>。</li><li><strong>隐藏层</strong>：没有激活函数，只是一个权重矩阵 <code>W</code>（大小为 <code>V x N</code>，其中 <code>N</code> 是我们想要的词向量维度，比如300）。<strong>这个权重矩阵 <code>W</code> 就是我们最终要学习的词向量表！</strong> 当 one-hot 向量输入时，实际上只是选中了 <code>W</code> 矩阵中的某一行。所以，<code>brown</code> 的词向量就是 <code>W</code> 矩阵的第三行。</li><li><strong>输出层</strong>：一个大小为 <code>V</code> 的向量，使用 Softmax 函数将其转换为概率分布，表示每个词作为上下文词出现的概率。</li></ul><p><strong>3. 训练过程：</strong></p><ul><li>我们输入 <code>brown</code> 的 one-hot 向量 <code>[0,0,1,0,0]</code>。</li><li>隐藏层计算：<code>隐藏向量 = 输入向量 · W</code>。由于输入是 one-hot，结果直接就是 <code>W</code> 矩阵中对应 <code>brown</code> 的那一行。我们称这个向量为 <code>v_brown</code>。</li><li>输出层计算：<code>输出向量 = 隐藏向量 · W‘</code>（这里 <code>W‘</code> 是另一个权重矩阵，可以理解为“上下文词向量矩阵”）。然后通过 Softmax 得到概率。</li><li>我们希望输出概率中，<code>The</code>, <code>quick</code>, <code>fox</code>, <code>jumps</code> 对应的位置的概率尽可能高。</li><li>通过反向传播和梯度下降（通常使用负采样技术来加速训练），不断调整权重矩阵 <code>W</code> 和 <code>W‘</code>。</li></ul><p><strong>4. 最终结果：</strong> 训练完成后，我们丢弃输出层，只保留<strong>隐藏层的权重矩阵 <code>W</code></strong>。这个矩阵的每一行，就对应词汇表中一个词的 <strong>词向量</strong>。</p><hr><h3 id="四、word2vec-的神奇之处-语义和语法关系" tabindex="-1">四、Word2Vec 的神奇之处：语义和语法关系 <a class="header-anchor" href="#四、word2vec-的神奇之处-语义和语法关系" aria-hidden="true">#</a></h3><p>词向量的强大之处在于，向量之间的空间关系反映了词语之间的语义和语法关系。</p><p><strong>1. 相似性：</strong> 词语 <code>king</code>、<code>queen</code>、<code>man</code>、<code>woman</code> 的向量在空间中会聚集在不同的“簇”中，但 <code>king</code> 和 <code>queen</code> 的距离，与 <code>man</code> 和 <code>woman</code> 的距离会非常相似。</p><p><strong>2. 类比关系（最著名的例子）：</strong></p><p><strong>“国王 - 男人 + 女人 ≈ 女王”</strong></p><p>用向量运算表示就是： <code>vector(‘king’) - vector(‘man’) + vector(‘woman’) ≈ vector(‘queen’)</code></p><p>这意味着词向量空间捕捉到了“性别”这一关系。</p><p>其他例子：</p><ul><li><code>vector(‘Paris’) - vector(‘France’) + vector(‘Italy’) ≈ vector(‘Rome’)</code> （首都关系）</li><li><code>vector(‘walked’) - vector(‘walking’) + vector(‘swimming’) ≈ vector(‘swam’)</code> （时态关系）</li></ul><hr><h3 id="五、关键技术与优化" tabindex="-1">五、关键技术与优化 <a class="header-anchor" href="#五、关键技术与优化" aria-hidden="true">#</a></h3><p>原始的 Word2Vec 训练效率很低，因为词汇表 <code>V</code> 可能非常大（数百万），导致输出层 Softmax 计算量巨大。因此引入了两种关键技术：</p><ol><li><p><strong>负采样</strong></p><ul><li><strong>思想</strong>：我们不再要求模型一次预测所有上下文词的概率。对于每个真实的（中心词，上下文词）对（正样本），我们随机从词汇表中抽取 <code>k</code> 个“非上下文”词（负样本）。</li><li><strong>新任务</strong>：训练模型将一个<strong>二分类任务</strong>：区分一个词对（中心词，目标词）是真实的上下文关系（正类）还是随机组合的关系（负类）。</li><li><strong>效果</strong>：这极大地简化了计算，成为训练 Word2Vec 的标准方法。论文中推荐小数据集 <code>k=5-20</code>，大数据集 <code>k=2-5</code>。</li></ul></li><li><p><strong>层次 Softmax</strong></p><ul><li><strong>思想</strong>：使用一棵哈夫曼树来表示整个词汇表，其中每个叶子节点代表一个单词。计算一个词的概率不再需要遍历整个词汇表，而只需要沿着树路径计算，复杂度从 <code>O(V)</code> 降为 <code>O(log(V))</code>。</li><li><strong>效果</strong>：同样是为了加速训练，尤其适用于低频词。</li></ul></li></ol><hr><h3 id="六、总结" tabindex="-1">六、总结 <a class="header-anchor" href="#六、总结" aria-hidden="true">#</a></h3><table><thead><tr><th style="text-align:left;">特性</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>核心思想</strong></td><td style="text-align:left;">基于分布假说，用上下文定义词义。</td></tr><tr><td style="text-align:left;"><strong>输出</strong></td><td style="text-align:left;">高维空间中的词向量（嵌入）。</td></tr><tr><td style="text-align:left;"><strong>主要模型</strong></td><td style="text-align:left;"><strong>CBOW</strong>（上下文预测中心词），<strong>Skip-gram</strong>（中心词预测上下文）。</td></tr><tr><td style="text-align:left;"><strong>关键创新</strong></td><td style="text-align:left;">简单的神经网络结构，配合<strong>负采样</strong>或<strong>层次Softmax</strong>进行高效训练。</td></tr><tr><td style="text-align:left;"><strong>核心能力</strong></td><td style="text-align:left;">捕捉词语的<strong>语义相似性</strong>和复杂的<strong>类比关系</strong>（如 king - man + woman = queen）。</td></tr><tr><td style="text-align:left;"><strong>应用</strong></td><td style="text-align:left;">作为几乎所有NLP任务的<strong>基础特征</strong>：文本分类、情感分析、机器翻译、智能问答、推荐系统等。</td></tr></tbody></table><p>Word2Vec 的意义在于，它首次用一种高效且可扩展的方式，将人类的语言词汇“数字化”为计算机能够理解和计算的数学对象（向量），并且这些向量中蕴含了丰富的语义信息，为后续的深度学习NLP研究奠定了坚实的基础。</p></div></div></main><!--[--><!--]--><footer class="VPDocFooter" data-v-dc19973f data-v-5440e431><!----><div class="prev-next" data-v-5440e431><div class="pager" data-v-5440e431><a class="pager-link prev" href="/AI/SERPAPI.html" data-v-5440e431><span class="desc" data-v-5440e431>Previous page</span><span class="title" data-v-5440e431>SERPAPI</span></a></div><div class="has-prev pager" data-v-5440e431><a class="pager-link next" href="/AI/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F.html" data-v-5440e431><span class="desc" data-v-5440e431>Next page</span><span class="title" data-v-5440e431>大模型应用开发模式</span></a></div></div></footer><!--[--><!--]--></div></div></div></div></div><footer class="VPFooter has-sidebar" data-v-9c83c81e data-v-0bba5d65><div class="container" data-v-0bba5d65><p class="message" data-v-0bba5d65>技术文档集合</p><p class="copyright" data-v-0bba5d65>Copyright © 2024</p></div></footer><!--[--><!--]--></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"ai_aigc.md\":\"c144be74\",\"ai_coze_dify.md\":\"8e6f38d8\",\"ai_ddg_serpapi.md\":\"5f39c7da\",\"ai_dashscope_modelscope.md\":\"5a39b6cc\",\"ai_faiss.md\":\"77709cbb\",\"ai_gpt架构.md\":\"e83afa7b\",\"ai_langchain.md\":\"97f283e3\",\"ai_lcel.md\":\"b1965b74\",\"ai_models.md\":\"19abd159\",\"ai_moe.md\":\"d6fd459f\",\"ai_nlp.md\":\"2e14501e\",\"ai_qianwen_vl.md\":\"ea34516b\",\"ai_rag.md\":\"53c2e445\",\"ai_serpapi.md\":\"b6c6b59b\",\"ai_transformer.md\":\"f6af52be\",\"ai_word2vec.md\":\"0edbca57\",\"ai_大模型应用开发模式.md\":\"6fa71c08\",\"ai_智能体系统设计.md\":\"abb6a42e\",\"ai_稠密向量-稀疏向量.md\":\"04d32546\",\"index.md\":\"31bd7a35\"}")</script>
    <script type="module" async src="/assets/app.23d277bf.js"></script>
    
  </body>
</html>