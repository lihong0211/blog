<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>技术文档 | 技术文档</title>
    <meta name="description" content="技术学习文档集合">
    <link rel="stylesheet" href="/assets/style.db59e0d6.css">
    <link rel="modulepreload" href="/assets/app.23d277bf.js">
    <link rel="modulepreload" href="/assets/AI_MOE.md.d6fd459f.lean.js">
    
    <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-9c83c81e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-be9c27de></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-be9c27de> Skip to content </a><!--]--><!----><header class="VPNav" data-v-9c83c81e data-v-bd98ce1b><div class="VPNavBar has-sidebar" data-v-bd98ce1b data-v-be850364><div class="container" data-v-be850364><div class="VPNavBarTitle has-sidebar" data-v-be850364 data-v-ef6bdfee><a class="title" href="/" data-v-ef6bdfee><!--[--><!--]--><!----><!--[-->技术文档<!--]--><!--[--><!--]--></a></div><div class="content" data-v-be850364><!--[--><!--]--><!----><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-be850364 data-v-4f0f7d90><span id="main-nav-aria-label" class="visually-hidden" data-v-4f0f7d90>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" data-v-4f0f7d90 data-v-d1df1d79 data-v-cbb71e82><!--[-->首页<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/AI/AIGC.html" data-v-4f0f7d90 data-v-d1df1d79 data-v-cbb71e82><!--[-->文档<!--]--><!----></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-be850364 data-v-6975dfb0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-6975dfb0 data-v-a11464a8 data-v-9b61e15c><span class="check" data-v-9b61e15c><span class="icon" data-v-9b61e15c><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-a11464a8><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-a11464a8><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-be850364 data-v-9d62d057 data-v-2aee37ba><!--[--><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-be850364 data-v-af83da42 data-v-0bf5642f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-0bf5642f><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-0bf5642f><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-0bf5642f><div class="VPMenu" data-v-0bf5642f data-v-958884f0><!----><!--[--><!--[--><!----><div class="group" data-v-af83da42><div class="item appearance" data-v-af83da42><p class="label" data-v-af83da42>Appearance</p><div class="appearance-action" data-v-af83da42><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-af83da42 data-v-a11464a8 data-v-9b61e15c><span class="check" data-v-9b61e15c><span class="icon" data-v-9b61e15c><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-a11464a8><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-a11464a8><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-af83da42><div class="item social-links" data-v-af83da42><div class="VPSocialLinks social-links-list" data-v-af83da42 data-v-2aee37ba><!--[--><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-be850364 data-v-cd76eed2><span class="container" data-v-cd76eed2><span class="top" data-v-cd76eed2></span><span class="middle" data-v-cd76eed2></span><span class="bottom" data-v-cd76eed2></span></span></button></div></div></div><!----></header><div class="VPLocalNav" data-v-9c83c81e data-v-05a75127><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-05a75127><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-05a75127><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-05a75127>Menu</span></button><a class="top-link" href="#" data-v-05a75127> Return to top </a></div><aside class="VPSidebar" data-v-9c83c81e data-v-66069f15><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-66069f15><span class="visually-hidden" id="sidebar-aria-label" data-v-66069f15> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-66069f15><section class="VPSidebarGroup" data-v-66069f15 data-v-7785691c><div class="title" data-v-7785691c><h2 class="title-text" data-v-7785691c>AI</h2><div class="action" data-v-7785691c><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="icon minus" data-v-7785691c><path d="M19,2H5C3.3,2,2,3.3,2,5v14c0,1.7,1.3,3,3,3h14c1.7,0,3-1.3,3-3V5C22,3.3,20.7,2,19,2zM20,19c0,0.6-0.4,1-1,1H5c-0.6,0-1-0.4-1-1V5c0-0.6,0.4-1,1-1h14c0.6,0,1,0.4,1,1V19z"></path><path d="M16,11H8c-0.6,0-1,0.4-1,1s0.4,1,1,1h8c0.6,0,1-0.4,1-1S16.6,11,16,11z"></path></svg><svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="icon plus" data-v-7785691c><path d="M19,2H5C3.3,2,2,3.3,2,5v14c0,1.7,1.3,3,3,3h14c1.7,0,3-1.3,3-3V5C22,3.3,20.7,2,19,2z M20,19c0,0.6-0.4,1-1,1H5c-0.6,0-1-0.4-1-1V5c0-0.6,0.4-1,1-1h14c0.6,0,1,0.4,1,1V19z"></path><path d="M16,11h-3V8c0-0.6-0.4-1-1-1s-1,0.4-1,1v3H8c-0.6,0-1,0.4-1,1s0.4,1,1,1h3v3c0,0.6,0.4,1,1,1s1-0.4,1-1v-3h3c0.6,0,1-0.4,1-1S16.6,11,16,11z"></path></svg></div></div><div class="items" data-v-7785691c><!--[--><!--[--><a class="VPLink link link" href="/AI/AIGC.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>AIGC</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/COZE_DIFY.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>COZE & DIFY</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/DashScope_ModelScope.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>DashScope & ModelScope</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/DDG_SERPAPI.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>DDG & SERPAPI</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/FAISS.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>FAISS</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/GPT%E6%9E%B6%E6%9E%84.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>GPT架构</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/LANGCHAIN.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>LANGCHAIN</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/LCEL.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>LCEL</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/MODELS.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>MODELS</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link active" href="/AI/MOE.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>MOE</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/NLP.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>NLP</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/QIANWEN_VL.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>QIANWEN VL</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/SERPAPI.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>SERPAPI</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/WORD2VEC.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>WORD2VEC</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>大模型应用开发模式</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>智能体系统设计</span><!--]--><!----></a><!----><!--]--><!--[--><a class="VPLink link link" href="/AI/%E7%A8%A0%E5%AF%86%E5%90%91%E9%87%8F-%E7%A8%80%E7%96%8F%E5%90%91%E9%87%8F.html" style="padding-left:0px;" data-v-5686a8aa data-v-cbb71e82><!--[--><span class="link-text" data-v-5686a8aa>稠密向量-稀疏向量</span><!--]--><!----></a><!----><!--]--><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-9c83c81e data-v-954ad629><div class="VPDoc has-sidebar has-aside" data-v-954ad629 data-v-dc19973f><div class="container" data-v-dc19973f><div class="aside" data-v-dc19973f><div class="aside-curtain" data-v-dc19973f></div><div class="aside-container" data-v-dc19973f><div class="aside-content" data-v-dc19973f><div class="VPDocAside" data-v-dc19973f data-v-63938968><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" data-v-63938968 data-v-72b1abc9><div class="content" data-v-72b1abc9><div class="outline-marker" data-v-72b1abc9></div><div class="outline-title" data-v-72b1abc9>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-72b1abc9><span class="visually-hidden" id="doc-outline-aria-label" data-v-72b1abc9> Table of Contents for current page </span><ul class="root" data-v-72b1abc9 data-v-a950ca15><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-63938968></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-dc19973f><div class="content-container" data-v-dc19973f><!--[--><!--]--><main class="main" data-v-dc19973f><div style="position:relative;" class="vp-doc _AI_MOE" data-v-dc19973f><div><h3 id="_1-什么是-moe" tabindex="-1">1. 什么是 MoE？ <a class="header-anchor" href="#_1-什么是-moe" aria-hidden="true">#</a></h3><p><strong>MoE</strong> 的全称是 <strong>Mixture of Experts</strong>，即<strong>混合专家</strong>。它是一种神经网络架构，其核心思想是：</p><p><strong>“分而治之”</strong>。与其让一个巨大的神经网络处理所有任务，不如训练一系列专门的“专家”网络，每个专家只擅长处理特定类型的数据或任务。然后，再有一个“门控网络”来根据输入数据，动态地决定将数据分配给哪一个或哪几个专家进行处理。</p><p>这就像一家医院，有内科、外科、眼科等不同专家。病人（输入数据）进来后，分诊台（门控网络）会根据病人的症状，将他引导到最合适的科室（专家网络）进行治疗。</p><hr><h3 id="_2-moe-的核心组件" tabindex="-1">2. MoE 的核心组件 <a class="header-anchor" href="#_2-moe-的核心组件" aria-hidden="true">#</a></h3><p>一个典型的 MoE 层包含两个核心部分：</p><ol><li><p><strong>专家网络</strong>：</p><ul><li>这些是功能相对简单（但本身也可以是深层网络）的子网络。</li><li>每个专家通常具有<strong>相同的网络结构</strong>（例如，都是前馈神经网络），但拥有<strong>不同的参数</strong>，因此它们会学习到不同的特征和模式。</li><li>在 Transformer 模型中，MoE 通常用来替换标准的前馈网络层。所以，每个“专家”本身就是一个前馈网络。</li></ul></li><li><p><strong>门控网络</strong>：</p><ul><li>这是一个小型神经网络，它的作用是<strong>根据当前的输入，计算每个专家被激活的权重或概率</strong>。</li><li>门控网络的输出是一个稀疏的权重向量，通常只有少数（比如 top-k）专家的权重非零。</li><li>最终输出是这些被选中的专家输出的加权和。</li></ul></li></ol><hr><h3 id="_3-moe-的工作流程" tabindex="-1">3. MoE 的工作流程 <a class="header-anchor" href="#_3-moe-的工作流程" aria-hidden="true">#</a></h3><p>假设我们有一个 MoE 层，其中有 <code>N</code> 个专家 <code>(E1, E2, ..., EN)</code>，门控网络为 <code>G</code>，输入为 <code>x</code>。</p><ol><li><strong>复制输入</strong>：输入 <code>x</code> 被复制 <code>N</code> 份，分别发送给门控网络和每一个专家网络。</li><li><strong>门控计算</strong>：门控网络 <code>G(x)</code> 接收输入，输出一个 <code>N</code> 维的概率分布向量 <code>g(x) = [g1, g2, ..., gN]</code>。这里 <code>gi</code> 表示输入 <code>x</code> 应该由专家 <code>Ei</code> 处理的概率或权重。</li><li><strong>选择专家</strong>：通常不会使用所有权重。系统会选择一个 <code>k</code> 值（例如 <code>k=2</code>），只保留权重最大的前 <code>k</code> 个专家，其余专家的权重置为0。这被称为 <strong>稀疏激活</strong>。这是 MoE 节省计算量的关键。</li><li><strong>专家计算</strong>：每个专家 <code>Ei</code> 独立地计算其输出 <code>Ei(x)</code>。</li><li><strong>加权合成</strong>：最终的 MoE 层输出 <code>y</code> 是前 <code>k</code> 个被选中专家的输出的加权和： <code>y = Σ_{i in top-k} gi * Ei(x)</code></li></ol><hr><h3 id="_4-举例说明" tabindex="-1">4. 举例说明 <a class="header-anchor" href="#_4-举例说明" aria-hidden="true">#</a></h3><p>让我们用一个具体的例子来形象化地理解这个过程。</p><p><strong>场景</strong>：一个用于判断文本情感的 MoE 模型（判断句子是积极/消极）。</p><p><strong>模型结构</strong>：</p><ul><li>我们有一个 MoE 层，包含 <strong>4 个专家</strong> <code>(E1, E2, E3, E4)</code>。</li><li>每个专家都是一个小的前馈神经网络。</li><li>门控网络 <code>G</code> 是一个线性层 + Softmax。</li><li>我们设置 <code>k=2</code>，即每次只激活 <strong>2 个</strong> 专家。</li></ul><p><strong>输入句子</strong>：</p><ol><li><code>“这个电影真是太精彩了，演员表演出色！”</code> （积极）</li><li><code>“服务很差，房间也很脏，体验糟糕透顶。”</code> （消极）</li></ol><p><strong>处理过程</strong>：</p><p><strong>对于句子1（积极）</strong>：</p><ol><li><strong>门控计算</strong>：门控网络 <code>G</code> 读入这个句子，计算出每个专家的权重： <ul><li><code>g(x) = [0.7, 0.25, 0.04, 0.01]</code></li><li>这意味着门控网络认为 <code>E1</code> 和 <code>E2</code> 最擅长处理这个输入。</li></ul></li><li><strong>选择专家</strong>：我们选择 top-2，即 <code>E1</code> 和 <code>E2</code>。<code>E3</code> 和 <code>E4</code> 被忽略，不进行计算。</li><li><strong>专家计算</strong>： <ul><li><code>E1</code>（可能擅长识别“强烈正面词汇”）接收到句子，输出一个向量 <code>O1</code>。</li><li><code>E2</code>（可能擅长识别“表演相关评价”）接收到句子，输出一个向量 <code>O2</code>。</li><li><code>E3</code> 和 <code>E4</code> <strong>不进行计算</strong>，节省了计算资源。</li></ul></li><li><strong>加权合成</strong>： <ul><li>最终输出 <code>y = 0.7 * O1 + 0.25 * O2</code>。</li></ul></li></ol><p><strong>对于句子2（消极）</strong>：</p><ol><li><strong>门控计算</strong>：门控网络 <code>G</code> 读入这个句子，计算出新的权重： <ul><li><code>g(x) = [0.1, 0.2, 0.6, 0.1]</code></li><li>此时，门控网络认为 <code>E3</code> 和 <code>E2</code> 最合适。</li></ul></li><li><strong>选择专家</strong>：选择 top-2，即 <code>E3</code> 和 <code>E2</code>。</li><li><strong>专家计算</strong>： <ul><li><code>E3</code>（可能擅长识别“服务和卫生问题”）输出向量 <code>O3</code>。</li><li><code>E2</code>（虽然句子2没提表演，但 <code>E2</code> 可能也泛化到了一些通用描述）输出向量 <code>O2</code>。</li><li><code>E1</code> 和 <code>E4</code> 被忽略。</li></ul></li><li><strong>加权合成</strong>： <ul><li>最终输出 <code>y = 0.6 * O3 + 0.2 * O2</code>。</li></ul></li></ol><p><strong>通过这个例子，你可以看到</strong>：</p><ul><li><strong>动态路由</strong>：对于不同的输入，门控网络动态地选择了不同的专家组合。</li><li><strong>稀疏性与效率</strong>：虽然我们有4个专家，但每个输入只计算了2个，理论上计算量只有使用全部4个专家的一半（实际有门控开销，但依然节省很多）。</li><li><strong>专家专业化</strong>：在训练过程中，<code>E1</code> 会更多地看到包含“精彩”等词的句子，从而变得更擅长处理积极情感；而 <code>E3</code> 则会更多地处理关于“服务”、“卫生”的抱怨，变得更擅长处理消极情感。专家们会自然地“分科”。</li></ul><hr><h3 id="_5-moe-的优势与挑战" tabindex="-1">5. MoE 的优势与挑战 <a class="header-anchor" href="#_5-moe-的优势与挑战" aria-hidden="true">#</a></h3><p><strong>优势</strong>：</p><ol><li><strong>巨量参数，恒定计算成本</strong>：这是 MoE 最大的优点。你可以将模型的总参数量扩展到万亿级别，但每个输入只激活一小部分参数，因此实际计算量（FLOPs）并不会随总参数线性增长。这使得训练超大规模模型成为可能。</li><li><strong>更强的表现力</strong>：不同的专家可以专注于不同的数据模式，让模型整体拥有更丰富的知识和能力。</li><li><strong>自然的多任务学习</strong>：不同的专家可以隐式地分配到不同的子任务上。</li></ol><p><strong>挑战与解决方案</strong>：</p><ol><li><strong>训练不稳定</strong>：门控网络和专家网络会相互影响，容易导致训练发散。需要精细的调参和特殊的损失函数。</li><li><strong>负载不均衡</strong>：门控网络可能倾向于总是选择那几个“热门”专家，导致其他专家得不到训练（“强者恒强”）。这就是<strong>专家负载不均衡</strong>问题。 <ul><li><strong>解决方案</strong>：在门控网络的损失函数中加入<strong>负载均衡损失</strong>，强制要求所有专家在 batch 层面上接收到大致相等的数据量。例如，Google 的 <strong>GShard</strong> 和 <strong>Switch Transformer</strong> 都采用了复杂的负载均衡策略。</li></ul></li><li><strong>通信开销</strong>：在分布式训练中，不同的专家可能被放在不同的设备（GPU）上。输入数据需要被路由到正确的设备，计算结果需要汇总，这会引入显著的通信开销。这就需要设计精巧的并行策略（如 <strong>专家并行</strong>）。</li></ol><hr><h3 id="_6-著名的实际应用案例" tabindex="-1">6. 著名的实际应用案例 <a class="header-anchor" href="#_6-著名的实际应用案例" aria-hidden="true">#</a></h3><ul><li><strong>Switch Transformer</strong>：Google 发布的模型，将 Transformer 中的每一个 FFN 层都替换成了 MoE 层。他们成功训练了具有<strong>万亿级别参数</strong>的模型，同时在保持计算成本可控的情况下，在多项任务上取得了优异表现。</li><li><strong>GShard</strong>：Google 推出的一个使 MoE 模型能够高效进行分布式训练的框架。</li><li><strong>Mixtral 8x7B</strong>：由 Mistral AI 发布的一个开源模型。它本质上是 <strong>一个“稀疏”的 Transformer 模型</strong>。其核心创新在于，每一层中的前馈网络层被一个 MoE 层所取代，这个 MoE 层包含 <strong>8 个</strong> 前馈网络“专家”，而对于每个输入 token，<strong>只激活其中的 2 个</strong>。所以，虽然它的总参数量高达 47B（近似于 8个7B模型），但实际运行时的计算成本只相当于一个 12.9B 的稠密模型，实现了高性能与高效率的完美结合。</li></ul><h3 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-hidden="true">#</a></h3><p>MoE 架构通过引入“专家”和“门控”的概念，巧妙地解决了模型规模扩大带来的计算成本爆炸问题。它实现了<strong>模型总参数（容量）与计算成本（效率）的解耦</strong>，是当前 scaling law 下推动大模型发展的一项至关重要的技术。你可以将其理解为一种高效的“委员会决策”机制，由门控网络担任主席，针对每个具体问题，召集最相关的几位专家开会决议，而不是让所有专家都对每个问题发表长篇大论。</p></div></div></main><!--[--><!--]--><footer class="VPDocFooter" data-v-dc19973f data-v-5440e431><!----><div class="prev-next" data-v-5440e431><div class="pager" data-v-5440e431><a class="pager-link prev" href="/AI/MODELS.html" data-v-5440e431><span class="desc" data-v-5440e431>Previous page</span><span class="title" data-v-5440e431>MODELS</span></a></div><div class="has-prev pager" data-v-5440e431><a class="pager-link next" href="/AI/NLP.html" data-v-5440e431><span class="desc" data-v-5440e431>Next page</span><span class="title" data-v-5440e431>NLP</span></a></div></div></footer><!--[--><!--]--></div></div></div></div></div><footer class="VPFooter has-sidebar" data-v-9c83c81e data-v-0bba5d65><div class="container" data-v-0bba5d65><p class="message" data-v-0bba5d65>技术文档集合</p><p class="copyright" data-v-0bba5d65>Copyright © 2024</p></div></footer><!--[--><!--]--></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"ai_aigc.md\":\"c144be74\",\"ai_coze_dify.md\":\"8e6f38d8\",\"ai_ddg_serpapi.md\":\"5f39c7da\",\"ai_dashscope_modelscope.md\":\"5a39b6cc\",\"ai_faiss.md\":\"77709cbb\",\"ai_gpt架构.md\":\"e83afa7b\",\"ai_langchain.md\":\"97f283e3\",\"ai_lcel.md\":\"b1965b74\",\"ai_models.md\":\"19abd159\",\"ai_moe.md\":\"d6fd459f\",\"ai_nlp.md\":\"2e14501e\",\"ai_qianwen_vl.md\":\"ea34516b\",\"ai_rag.md\":\"53c2e445\",\"ai_serpapi.md\":\"b6c6b59b\",\"ai_transformer.md\":\"f6af52be\",\"ai_word2vec.md\":\"0edbca57\",\"ai_大模型应用开发模式.md\":\"6fa71c08\",\"ai_智能体系统设计.md\":\"abb6a42e\",\"ai_稠密向量-稀疏向量.md\":\"04d32546\",\"index.md\":\"31bd7a35\"}")</script>
    <script type="module" async src="/assets/app.23d277bf.js"></script>
    
  </body>
</html>